MODEL_RUNNER_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/
MODEL_RUNNER_BASE_URL=http://localhost:12434/engines/llama.cpp/v1/
#MODEL_RUNNER_BASE_URL=http://localhost:13434/engines/llama.cpp/v1/

#MODEL_RUNNER_TOOL_LLM=ignaciolopezluna020/watt-tool:8B-Q4_K_M
#MODEL_RUNNER_TOOL_LLM=ignaciolopezluna020/llama-xlam:8B-Q4_K_M

MODEL_RUNNER_TOOL_LLM=ai/qwen2.5:1.5B-F16
#MODEL_RUNNER_TOOL_LLM=ai/qwen2.5:latest
#MODEL_RUNNER_CHAT_LLM=ai/llama3.2:latest

# Test with LlamaFile
#MODEL_RUNNER_CHAT_LLM=Qwen2.5-0.5B-Instruct-Q6_K.gguf
#MODEL_RUNNER_BASE_URL=http://127.0.0.1:8080/v1/
#MODEL_RUNNER_TOOL_LLM=Qwen2.5-0.5B-Instruct-Q6_K.gguf