MODEL_RUNNER_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/
#MODEL_RUNNER_BASE_URL=http://localhost:12434/engines/llama.cpp/v1/
MODEL_RUNNER_TOOL_LLM=ai/qwen2.5:1.5B-F16
MODEL_RUNNER_CHAT_LLM=ai/llama3.2:latest


OLLAMA_BASE_URL=http://host.docker.internal:11434/v1
# OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_TOOL_LLM=qwen2.5:1.5b
OLLAMA_CHAT_LLM=llama3.2:1b